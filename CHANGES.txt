1.2.0

1.1.0
 * Add an ./sbt/sbt script (like with spark) so people don't need to install sbt
 * Replace internal spark Logging with own class (#245)
 * Accept partition key predicates in CassandraRDD#where. (#37)
 * Add indexedColumn to ColumnDef (#122)
 * Upgrade Spark to version 1.0.2 
 * Removed deprecated toArray, replaced with collect.
 * Updated imports to org.apache.spark.streaming.receiver
   and import org.apache.spark.streaming.receiver.ActorHelper
 * Updated streaming demo and spec for Spark 1.0.2 behavior compatibility
 * Added new StreamingEvent types for Spark 1.0.2 Receiver readiness
 * Added the following Spark Streaming dependencies to the demos module:
   Kafka, Twitter, ZeroMQ
 * Added embedded Kafka and ZooKeeper servers for the Kafka Streaming demo
   - keeping non private for user prototyping
 * Added new Kafka Spark Streaming demo which reads from Kafka
   and writes to Cassandra (Twitter and ZeroMQ are next)
 * Added new 'embedded' module
   - Refactored the 'connector' module's IT SparkRepl, CassandraServer and CassandraServerRunner as
     well as 'demos' EmbeddedKafka and EmbeddedZookeeper to the 'embedded' module. This allows the 'embedded'
     module to be used as a dependency by the 'connector' IT tests, demos, and user local quick prototyping
     without requiring a Spark and Cassandra Cluster, local or remote, to get started.

1.0.0
 * Fix memory leak in PreparedStatementCache leaking PreparedStatements after
   closing Cluster objects. (#183)
 * Allow multiple comma-separated hosts in spark.cassandra.connection.host

1.0.0 RC 6
 * Fix reading a Cassandra table as an RDD of Scala class objects in REPL

1.0.0 RC 5
 * Added assembly task to the build, in order to build fat jars. (#126)
   - Added a system property flag to enable assembly for the demo module which is disabled by default.
   - Added simple submit script to submit a demo assembly jar to a local spark master
 * Fix error message on column conversion failure. (#208)
 * Add toMap and nameOf methods to CassandraRow.
   Reduce size of serialized CassandraRow. (#194)
 * Fixed a bug which caused problems with connecting to Cassandra under
   heavy load (#185)
 * Skip $_outer constructor param in ReflectionColumnMapper, fixes working with
   case classes in Spark shell, added appropriate test cases (#188)
 * Added streaming demo with documentation, new streaming page to docs, new README for running all demos. (#115)

1.0.0 RC 4
 * Upgrade Java driver for Cassandra to 2.0.4. (#171)
 * Added missing CassandraRDD#getPreferredLocations to improve data-locality. (#164)
 * Don't use hosts outside the datacenter of the connection host. (#137)

1.0.0 RC 3
 * Fix open Cluster leak in CassandraConnector#createSession (#142)
 * TableWriter#saveToCassandra accepts ColumnSelector instead of Seq[String] for
   passing a column list. Seq[String] still accepted for backwards compatibility,
   but deprecated.
 * Added Travis CI build yaml file.
 * Added demos module. (#84)
 * Extracted Java API into a separate module (#99)

1.0.0 RC 2
 * Language specific highlighting in the documentation (#105)
 * Fixed a bug which caused problems when a column of VarChar type was used
   in where clause. (04fd8d9)
 * Fixed an AnyObjectFactory bug which caused problems with instantiation of
   classes which were defined inside Scala objects. (#82)
 * Added support for Spark Streaming. (#89)
    - Added implicit wrappers which simplify access to Cassandra related
      functionality from StreamingContext and DStream.
    - Added a stub for further Spark Streaming integration tests.
 * Upgraded Java API. (#98)
    - Refactored existing Java API
    - Added CassandraJavaRDD as a JAVA counterpart of CassandraRDD
    - Added Java helpers for accessing Spark Streaming related methods
    - Added several integration tests
    - Added a documentation page for JAVA API
    - Extended Java API demo
    - Added a lot of API docs

1.0.0 RC 1
 * Ability to register custom TypeConverters. (#32)
 * Handle null values in StringConverter. (#79)
 * Improved error message when there are no replicas in the local DC. (#69)

1.0.0 beta 2
 * DSE compatibility improvements. (#64)
    - Column types and type converters use TypeTags instead of Strings to
      announce their types.
    - CassandraRDD#tableDef is public now.
    - Added methods for getting keyspaces and tables by name from the Schema.
    - Refactored Schema class - loading schema from Cassandra moved
      from the constructor to a factory method.
    - Remove unused methods for returning system keyspaces from Schema.
 * Improved JavaDoc explaining CassandraConnector withClusterDo
   and withSessionDo semantics.
 * Support for updating counter columns. (#27)
 * Configure consistency level for reads/writes. Set default consistency
   levels to LOCAL_ONE for reads and writes. (#42)
 * Values passed as arguments to `where` are converted to proper types
   expected by the java-driver. (#26)
 * Include more information in the exception message when query in
   CassandraRDD fails. (#69)
 * Fallback to describe_ring in case describe_local_ring does not exist to
   improve compatibility with earlier Cassandra versions. (#47)
 * Session object sharing in CassandraConnector. (#41 and #53)
 * Modify cassandra.* configuration settings to prefix with "spark." so they
   can be used from spark-shell and set via conf/spark-default.conf (#51)
 * Fixed race condition in AsyncExecutor causing inaccuracy of success/failure
   counters. (#40)
 * Added Java API. Fixed a bug in ClassBasedRowReader which caused
   problems when data were read into Java beans. Added type converters
   for boxed Java primitive types. (#11)
 * Extracted out initial testkit for unit and integration tests, and future testkit module.
 * Added new WritableToCassandra trait which both RDDFunction and DStreamFunction both implement.
   Documentation moved to WritableToCassandra.
 * Fixed broken links in API documentation.
 * Refactored RDDFunctions and DStreamFunctions - merged saveToCassandra overloaded methods into a single method with defaults.

1.0.0 beta 1
 * CassandraRDD#createStatement doesn't obtain a new session, but reuses
   the task's Session.
 * Integration tests. (#12)
 * Added contains and indexOf methods to CassandraRow. Missing value from
   CassandraRow does not break writing - null is written instead.
 * Caching of PreparedStatements. Subsequent preparations of the same
   PreparedStatement are returned from the cache and don't cause
   a warning. (#3)
 * Move partitioner ForkJoinPool to companion object to share it between RDD's.
   (#24)
 * Fixed thread-safety of ClassBasedRowReader.
 * Detailed user guide with code examples, reviewed by Kris Hahn. (#15)
 * Support for saving RDD[CassandraRow]. New demo program copying data from one
   table to another. (#16)
 * Using a PreparedStatement make createStatement method compatible with
   Cassandra 1.2.x. (#17)
 * More and better logging. Using org.apache.spark.Logging instead of log4j.
   (#13)
 * Better error message when attempting to write to a table that doesn't exist.
   (#1)
 * Added more robust scala build to allow for future clean releases, and
   publish settings for later integration. (#8)
 * Refactored classes and objects used for authentication to support pluggable
   authentication.
 * Record cause of TypeConversionException.
 * Improved error messages informing about failure to convert column value.
   Fixed missing conversion for setters.
 * Split CassandraWriter into RowWriter and TableWriter.
 * Refactored package structure. Moved classes from rdd to rdd.reader
   and rdd.partitioner packages. Renamed RowTransformers to RowReaders.
 * Fix writing ByteBuffers to Cassandra.
 * Throw meaningful exception when non-existing column is requested by name.
 * Add isNull method on CassandraRow.
 * Fix converting blobs to arrays of bytes in CassandraRow. Fix printing blobs
   and collections.
